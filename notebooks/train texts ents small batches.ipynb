{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import ujson as json\n",
    "import csv\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "from spacy.util import read_json, minibatch, compounding, decaying, load_model_from_path\n",
    "from lang.fr import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"../models/plays-small-batches\")\n",
    "resume_from_epoch = 880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path_glob, name):\n",
    "    files = glob(path_glob)\n",
    "    data = []\n",
    "    for filepath in files:\n",
    "        data.append(read_json(filepath))\n",
    "\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    print(\"Loaded %d %s files\" % (len(data), name))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../training/fulltext*.json'\n",
    "evaluation_path = '../training/evaluation/fulltext*.json'\n",
    "\n",
    "def reload_data():\n",
    "    print(\"Reload data\")\n",
    "    train_data = load_files(train_path, \"train\")\n",
    "    test_data = load_files(evaluation_path, \"test\")\n",
    "    \n",
    "    return (train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_scorable():\n",
    "    paths = glob(train_path) + glob(evaluation_path)\n",
    "    for path in paths:\n",
    "        text, annotations = read_json(path)\n",
    "        \n",
    "        doc = nlp.make_doc(text)\n",
    "        gold = GoldParse(doc, **annotations)\n",
    "        \n",
    "        prediction = nlp(text)\n",
    "\n",
    "        scorer = Scorer()\n",
    "        scorer.score(prediction, gold)\n",
    "\n",
    "        status = \"NOOK\" if scorer.scores['ents_p'] == 0 else \"OK\"\n",
    "\n",
    "        if status == \"NOOK\":\n",
    "            os.rename(path, f\"{path}.error\")\n",
    "\n",
    "        print(\n",
    "            \"{:<5}\".format(status),\n",
    "            \"{:<40}\".format(path),\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_path, evaluation_data):\n",
    "    nlp_loaded = load_model_from_path(model_path)\n",
    "    model.configure(nlp_loaded)\n",
    "    \n",
    "    scorer = Scorer()\n",
    "    for (text, annotations) in evaluation_data:\n",
    "        doc = nlp_loaded.make_doc(text)\n",
    "        gold = GoldParse(doc, **annotations)\n",
    "        prediction = nlp_loaded(text)\n",
    "\n",
    "        scorer.score(prediction, gold)\n",
    "    \n",
    "    acc_loc = (model_path / 'accuracy.json')\n",
    "    with acc_loc.open('w') as file_:\n",
    "        file_.write(json.dumps(scorer.scores))\n",
    "            \n",
    "    return scorer\n",
    "\n",
    "    del nlp_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path, optimizer):\n",
    "    model.meta['name'] = \"plays\"\n",
    "    with model.use_params(optimizer.averages):\n",
    "        model.to_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_from_epoch is None:\n",
    "    # nlp = spacy.blank('fr')\n",
    "    # optimizer = nlp.begin_training()\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "else:\n",
    "    model_path = output_path / ('epoch-%03d' % (resume_from_epoch - 1))\n",
    "    nlp = load_model_from_path(model_path)\n",
    "    \n",
    "model.configure(nlp)\n",
    "optimizer = nlp.entity.create_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')\n",
    "    \n",
    "\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ('ACT', 'SCENE', 'OTHER-SEP', 'SPEAKER', 'M-SPEAKERS', 'COMMENT', 'HEAD-COMMENT',\n",
    "          'PAGE-NUMBER', 'FOOTER')\n",
    "for label in LABELS:\n",
    "    ner.add_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK    ../training/fulltext-636.json           \n",
      "OK    ../training/fulltext-sample.json        \n",
      "OK    ../training/fulltext-616.json           \n",
      "OK    ../training/fulltext-354.json           \n",
      "OK    ../training/fulltext-641.json           \n",
      "OK    ../training/fulltext-15.json            \n",
      "OK    ../training/fulltext-355.json           \n",
      "OK    ../training/fulltext-640.json           \n",
      "OK    ../training/fulltext-617.json           \n",
      "OK    ../training/fulltext-441.json           \n",
      "OK    ../training/fulltext-380.json           \n",
      "OK    ../training/fulltext-38.json            \n",
      "OK    ../training/fulltext-379.json           \n",
      "OK    ../training/fulltext-512.json           \n",
      "OK    ../training/fulltext-318.json           \n",
      "OK    ../training/fulltext-363.json           \n",
      "OK    ../training/fulltext-22.json            \n",
      "OK    ../training/fulltext-637.json           \n",
      "OK    ../training/fulltext-515.json           \n",
      "OK    ../training/fulltext-407.json           \n",
      "OK    ../training/fulltext-610.json           \n",
      "OK    ../training/fulltext-240.json           \n",
      "OK    ../training/fulltext-352.json           \n",
      "OK    ../training/fulltext-647.json           \n",
      "OK    ../training/fulltext-630.json           \n",
      "OK    ../training/fulltext-237.json           \n",
      "OK    ../training/fulltext-372.json           \n",
      "OK    ../training/fulltext-364.json           \n",
      "OK    ../training/fulltext-626.json           \n",
      "OK    ../training/fulltext-308.json           \n",
      "OK    ../training/fulltext-349.json           \n",
      "OK    ../training/fulltext-627.json           \n",
      "OK    ../training/fulltext-365.json           \n",
      "OK    ../training/fulltext-236.json           \n",
      "OK    ../training/fulltext-631.json           \n",
      "OK    ../training/fulltext-12.json            \n",
      "OK    ../training/fulltext-353.json           \n",
      "OK    ../training/fulltext-646.json           \n",
      "OK    ../training/fulltext-312.json           \n",
      "OK    ../training/fulltext-607.json           \n",
      "OK    ../training/fulltext-650.json           \n",
      "OK    ../training/fulltext-429.json           \n",
      "OK    ../training/fulltext-645.json           \n",
      "OK    ../training/fulltext-350.json           \n",
      "OK    ../training/fulltext-612.json           \n",
      "OK    ../training/fulltext-604.json           \n",
      "OK    ../training/fulltext-595.json           \n",
      "OK    ../training/fulltext-444.json           \n",
      "OK    ../training/fulltext-628.json           \n",
      "OK    ../training/fulltext-385.json           \n",
      "OK    ../training/fulltext-1046.json          \n",
      "OK    ../training/fulltext-608.json           \n",
      "OK    ../training/fulltext-624.json           \n",
      "OK    ../training/fulltext-370.json           \n",
      "OK    ../training/fulltext-633.json           \n",
      "OK    ../training/fulltext-263.json           \n",
      "OK    ../training/fulltext-388.json           \n",
      "OK    ../training/fulltext-625.json           \n",
      "OK    ../training/fulltext-609.json           \n",
      "OK    ../training/fulltext-424.json           \n",
      "OK    ../training/fulltext-561.json           \n",
      "OK    ../training/fulltext-238.json           \n",
      "OK    ../training/fulltext-384.json           \n",
      "OK    ../training/fulltext-347.json           \n",
      "OK    ../training/fulltext-605.json           \n",
      "OK    ../training/fulltext-613.json           \n",
      "OK    ../training/fulltext-644.json           \n",
      "OK    ../training/fulltext-618.json           \n",
      "OK    ../training/fulltext-474.json           \n",
      "OK    ../training/fulltext-337.json           \n",
      "OK    ../training/fulltext-634.json           \n",
      "OK    ../training/fulltext-17.json            \n",
      "OK    ../training/fulltext-643.json           \n",
      "OK    ../training/fulltext-356.json           \n",
      "OK    ../training/fulltext-614.json           \n",
      "OK    ../training/fulltext-317.json           \n",
      "OK    ../training/fulltext-638.json           \n",
      "OK    ../training/fulltext-140.json           \n",
      "OK    ../training/fulltext-253.json           \n",
      "OK    ../training/fulltext-316.json           \n",
      "OK    ../training/fulltext-615.json           \n",
      "OK    ../training/fulltext-41.json            \n",
      "OK    ../training/fulltext-642.json           \n",
      "OK    ../training/fulltext-357.json           \n",
      "OK    ../training/fulltext-635.json           \n",
      "OK    ../training/fulltext-36.json            \n",
      "OK    ../training/fulltext-20.json            \n",
      "OK    ../training/fulltext-336.json           \n",
      "OK    ../training/fulltext-619.json           \n",
      "OK    ../training/evaluation/fulltext-694.json\n",
      "OK    ../training/evaluation/fulltext-657.json\n",
      "OK    ../training/evaluation/fulltext-986.json\n",
      "OK    ../training/evaluation/fulltext-695.json\n",
      "OK    ../training/evaluation/fulltext-924.json\n",
      "OK    ../training/evaluation/fulltext-1018.json\n",
      "OK    ../training/evaluation/fulltext-1044.json\n",
      "OK    ../training/evaluation/fulltext-942.json\n",
      "OK    ../training/evaluation/fulltext-653.json\n",
      "OK    ../training/evaluation/fulltext-652.json\n",
      "OK    ../training/evaluation/fulltext-989.json\n",
      "OK    ../training/evaluation/fulltext-696.json\n",
      "OK    ../training/evaluation/fulltext-679.json\n",
      "OK    ../training/evaluation/fulltext-697.json\n",
      "OK    ../training/evaluation/fulltext-654.json\n",
      "OK    ../training/evaluation/fulltext-658.json\n",
      "Reload data\n",
      "Loaded 89 train files\n",
      "Loaded 16 test files\n"
     ]
    }
   ],
   "source": [
    "ensure_scorable()\n",
    "train_data, test_data = reload_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_path = output_path / \"stats.csv\"\n",
    "if resume_from_epoch is not None:\n",
    "    stats_file = open(stats_path, \"a\")\n",
    "    stats_csv = csv.writer(stats_file)\n",
    "else:\n",
    "    stats_file = open(stats_path, \"w\")\n",
    "    stats_csv = csv.writer(stats_file)\n",
    "    stats_csv.writerow([\"epoch\", \"start_at\", \"end_at\", \"duration\", \"losses_ner\", \"ents_p\", \"ents_r\", \"ents_f\"])\n",
    "\n",
    "def write_stats(epoch, start_at, end_at, losses, scores):\n",
    "    stats_csv.writerow([\n",
    "        epoch,\n",
    "        start_at, \n",
    "        end_at,\n",
    "        end_at - start_at, \n",
    "        losses['ner'],\n",
    "        scores.get(\"ents_p\", None),\n",
    "        scores.get(\"ents_r\", None),\n",
    "        scores.get(\"ents_f\", None),\n",
    "    ])\n",
    "    \n",
    "    stats_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training at 2019-01-08 01:31:09.729845\n",
      "Reload data\n",
      "Loaded 89 train files\n",
      "Loaded 16 test files\n",
      "Epoch %d\n"
     ]
    }
   ],
   "source": [
    "training_start_at = datetime.datetime.now()\n",
    "print(\"Start training at\", training_start_at)\n",
    "\n",
    "best_loss = None\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "\n",
    "dropout = decaying(0.4, 0.2, 1e-4)\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    for epoch in range(resume_from_epoch or 0, 2000):\n",
    "        start_at = datetime.datetime.now()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            train_data, test_data = reload_data()\n",
    "            \n",
    "        random.shuffle(train_data)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(train_data, size=compounding(1.1, 8., 1.001))\n",
    "   \n",
    "        drop = next(dropout)\n",
    "        for batch in batches:  \n",
    "            texts, annotations = zip(*batch)\n",
    "\n",
    "            try:\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=drop, losses=losses)\n",
    "            except:\n",
    "                print(\"Problem with\", texts, annotations)\n",
    "                raise\n",
    "                    \n",
    "        epoch_model_path = output_path / ('epoch-%03d' % epoch)\n",
    "        \n",
    "        save_model(nlp, epoch_model_path,  optimizer=optimizer)\n",
    "        \n",
    "        if best_loss is None or losses['ner'] < best_loss:\n",
    "            best_loss = losses['ner']\n",
    "            \n",
    "        if epoch % 5 == 0 or best_loss == losses['ner']:\n",
    "            scores = evaluate(epoch_model_path, test_data).scores\n",
    "        else:\n",
    "            scores = {}\n",
    "        \n",
    "        end_at = datetime.datetime.now()\n",
    "        \n",
    "        write_stats(epoch, start_at, end_at, losses, scores)\n",
    "       \n",
    "        print(f'Epoch {epoch}')\n",
    "            \n",
    "            \n",
    "stats_file.close()\n",
    "training_end_at = datetime.datetime.now()\n",
    "print('Training ended at', training_end_at, 'took', training_end_at - training_start_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = output_path / 'model-final'\n",
    "save_model(nlp, model_path, optimizer=optimzer)\n",
    "scorer = evaluate(model_path)\n",
    "print(\"Accuracy: \", scorer.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
